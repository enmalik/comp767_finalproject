{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# from tensorflow.python.keras.layers import Dense\n",
    "# from tensorflow.python.keras import Sequential\n",
    "# from tensorflow.python.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some constants and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "discount = 0.9\n",
    "epsilon = 0.1\n",
    "memory_cap = 999999999\n",
    "# n_step = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classes for different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replay_Default():\n",
    "    \n",
    "    def __init__(self, buffer_size=50):\n",
    "        self.experience = []\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning:\n",
    "    \n",
    "    def __init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning_Default:\n",
    "    \n",
    "    def __init__(self, o_space, a_space, buffer, lr, n_step):\n",
    "        self.n_step = n_step\n",
    "        self.a_space = a_space\n",
    "        self.buffer = buffer\n",
    "        self.lr = lr\n",
    "        self.experience = deque(maxlen=memory_cap)\n",
    "        \n",
    "        self.clf = Sequential()\n",
    "        self.clf.add(Dense(64, input_shape=(o_space,), activation=\"relu\"))\n",
    "        self.clf.add(Dense(64, activation=\"relu\"))\n",
    "        self.clf.add(Dense(self.a_space, activation=\"linear\"))\n",
    "        self.clf.compile(loss=\"mse\", optimizer=Adam(lr=lr))\n",
    "        \n",
    "        self.reset_multistep_exp()\n",
    "        \n",
    "    def add_experience(self, s, a, r, s_next, terminal):\n",
    "        self.multistep_step += 1\n",
    "        self.multistep_rewards.append(r)\n",
    "        \n",
    "        if self.multistep_step == 1:\n",
    "            self.multistep_state = s\n",
    "            self.multistep_action = a\n",
    "        \n",
    "        if self.multistep_step == self.n_step:\n",
    "            reward = 0\n",
    "            \n",
    "            for i in range(len(self.multistep_rewards)):\n",
    "                step_reward = self.multistep_rewards[i]\n",
    "                reward += (discount ** i) * step_reward\n",
    "                \n",
    "            self.experience.append([self.multistep_state, self.multistep_action, reward, s_next, terminal])\n",
    "            self.reset_multistep_exp()\n",
    "        \n",
    "    def reset_multistep_exp(self):\n",
    "        self.multistep_step = 0\n",
    "        self.multistep_state = None\n",
    "        self.multistep_action = None\n",
    "        self.multistep_rewards = []\n",
    "        \n",
    "    def get_action(self, s):\n",
    "        random_explore = np.random.rand()\n",
    "        \n",
    "        if random_explore < epsilon:\n",
    "            return random.randrange(self.a_space)\n",
    "        \n",
    "        q_vals = self.clf.predict(s)\n",
    "        \n",
    "        return np.argmax(q_vals[0])\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        if len(self.experience) < self.buffer:\n",
    "            return\n",
    "        \n",
    "        exp_batch = random.sample(self.experience, self.buffer)\n",
    "        \n",
    "        for s, a, r, s_next, terminal in exp_batch:\n",
    "            q_update = r\n",
    "            \n",
    "            if not terminal:\n",
    "                q_update = (r + discount * np.amax(self.clf.predict(s_next)[0]))\n",
    "            \n",
    "            q_vals = self.clf.predict(s)\n",
    "            q_vals[0][a] = q_update\n",
    "            self.clf.fit(s, q_vals, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Q_Learning_Default_NP:\n",
    "    \n",
    "#     def __init__(self, o_space, a_space, buffer, lr, n_step, state_shape):\n",
    "#         self.n_step = n_step\n",
    "#         self.a_space = a_space\n",
    "#         self.buffer = buffer\n",
    "#         self.lr = lr\n",
    "        \n",
    "#         self.memory_cap = memory_cap\n",
    "#         self.st_idx = 0\n",
    "#         self.memory_size = 0\n",
    "        \n",
    "#         state_list_shape = [self.memory_cap] + list(state_shape)\n",
    "        \n",
    "#         self.s = np.zeros(state_list_shape, dtype=float)\n",
    "#         self.a = np.zeros(memory_cap, dtype=int)\n",
    "#         self.r = np.zeros(memory_cap, dtype=float)\n",
    "#         self.s_next = np.zeros(state_list_shape, dtype=float)\n",
    "#         self.terminal = np.zeros(memory_cap, dtype=bool)\n",
    "                \n",
    "#         self.clf = Sequential()\n",
    "#         self.clf.add(Dense(64, input_shape=state_shape, activation=\"relu\"))\n",
    "#         self.clf.add(Dense(64, activation=\"relu\"))\n",
    "#         self.clf.add(Dense(self.a_space, activation=\"linear\"))\n",
    "#         self.clf.compile(loss=\"mse\", optimizer=Adam(lr=lr))\n",
    "        \n",
    "#     def add_experience(self, s, a, r, s_next, terminal):\n",
    "#         self.s[self.st_idx] = s\n",
    "#         self.a[self.st_idx] = a\n",
    "#         self.r[self.st_idx] = r\n",
    "#         self.s_next[self.st_idx] = s_next\n",
    "#         self.terminal[self.st_idx] = terminal\n",
    "        \n",
    "#         if self.memory_size < self.memory_cap:\n",
    "#             self.memory_size += 1\n",
    "            \n",
    "#         self.st_idx += 1\n",
    "        \n",
    "#         if self.st_idx >= self.memory_cap:\n",
    "#             self.st_idx = 0 # resetting at 0\n",
    "        \n",
    "#     def get_action(self, s):\n",
    "#         random_explore = np.random.rand()\n",
    "        \n",
    "#         if random_explore < epsilon:\n",
    "#             return random.randrange(self.a_space)\n",
    "        \n",
    "#         q_vals = self.clf.predict(s)\n",
    "        \n",
    "#         return np.argmax(q_vals[0])\n",
    "    \n",
    "#     def experience_replay(self):\n",
    "#         min_buffer_len = np.min([self.memory_size, self.buffer])\n",
    "#         idx = np.random.randint(low=0, high=self.memory_size, size=min_buffer_len, dtype=int)\n",
    "#         s_batch = self.s[idx]\n",
    "#         a_batch = self.a[idx]\n",
    "#         r_batch = self.r[idx]\n",
    "#         s_next_batch = self.s_next[idx]\n",
    "#         terminal_batch = self.terminal[idx]\n",
    "\n",
    "#         for i in range(len(s_batch)):\n",
    "#             s = np.array([s_batch[i]])\n",
    "#             a = a_batch[i]\n",
    "#             r = r_batch[i]\n",
    "#             s_next = np.array([s_next_batch[i]])\n",
    "#             terminal = terminal_batch[i]\n",
    "            \n",
    "#             q_update = r\n",
    "            \n",
    "#             if not terminal:\n",
    "#                 q_update = (r + discount * np.amax(self.clf.predict(s_next)[0]))\n",
    "            \n",
    "#             q_vals = self.clf.predict(s)\n",
    "#             q_vals[0][a] = q_update\n",
    "# #             print(type(q_vals))\n",
    "# #             print(type(s))\n",
    "#             self.clf.fit(s, q_vals, verbose=0)\n",
    "            \n",
    "#         time_d = time.time()\n",
    "        \n",
    "#         a_perc = (time_b - time_a) / (time_d - time_a)\n",
    "#         b_perc = (time_c - time_b) / (time_d - time_a)\n",
    "#         c_perc = (time_d - time_c) / (time_d - time_a)\n",
    "# #         d_perc = (time_e - time_d) / (time_e - time_a)\n",
    "\n",
    "# #         print(\"a\", a_perc*100)\n",
    "# #         print(\"b\", b_perc*100)\n",
    "# #         print(\"c\", c_perc*100)\n",
    "# #         print(\"d\", d_perc*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning_HER:\n",
    "    \n",
    "    def __init__(self, o_space, a_space, buffer, lr, n_step):\n",
    "        self.n_step = n_step\n",
    "        self.a_space = a_space\n",
    "        self.buffer = buffer\n",
    "        self.lr = lr\n",
    "        self.experience = []#deque(maxlen=memory_cap)\n",
    "        self.her_experience = []#deque(maxlen=memory_cap)\n",
    "        \n",
    "        self.clf = Sequential()\n",
    "        self.clf.add(Dense(64, input_shape=(o_space,), activation=\"relu\"))\n",
    "        self.clf.add(Dense(64, activation=\"relu\"))\n",
    "        self.clf.add(Dense(self.a_space, activation=\"linear\"))\n",
    "        self.clf.compile(loss=\"mse\", optimizer=Adam(lr=lr))\n",
    "        \n",
    "    def add_experience(self, s, a, r, s_next, terminal):\n",
    "        self.experience.append([s, a, r, s, terminal])\n",
    "        \n",
    "    def add_her_experience(self, s, a, r, s_next, terminal):\n",
    "        self.her_experience.append([s, a, r, s, terminal])\n",
    "        \n",
    "    def get_action(self, s):\n",
    "        random_explore = np.random.rand()\n",
    "        \n",
    "        if random_explore < epsilon:\n",
    "            return random.randrange(self.a_space)\n",
    "        \n",
    "        q_vals = self.clf.predict(s)\n",
    "        \n",
    "        return np.argmax(q_vals[0])\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        min_buffer_len = np.min([len(self.experience), self.buffer])\n",
    "        \n",
    "        exp_batch = random.sample(self.experience, min_buffer_len)\n",
    "        \n",
    "        for s, a, r, s_next, terminal in exp_batch:\n",
    "            q_update = r\n",
    "            \n",
    "            if not terminal:\n",
    "                q_update = (r + discount * np.amax(self.clf.predict(s_next)[0]))\n",
    "            \n",
    "            q_vals = self.clf.predict(s)\n",
    "            q_vals[0][a] = q_update\n",
    "            self.clf.fit(s, q_vals, verbose=0)\n",
    "            \n",
    "    def modify_her_list(self):\n",
    "        new_her_experience = copy.deepcopy(self.her_experience)\n",
    "        new_her_len = len(new_her_experience)\n",
    "        her_goal = self.her_experience[-1][3]\n",
    "        \n",
    "        for i in range(new_her_len):\n",
    "            new_her_experience[-1-i][0] = her_goal\n",
    "            new_her_experience[-1-i][2] = -1.0\n",
    "            new_her_experience[-1-i][3] = her_goal\n",
    "            new_her_experience[-1-i][4] = False\n",
    "            \n",
    "            if (np.sum(np.abs((new_her_experience[-1-i][4] - her_goal))) == 0):\n",
    "                new_her_experience[-1-i][2] = 0.0\n",
    "                new_her_experience[-1-i][4] = True\n",
    "        \n",
    "        for hx in new_her_experience:\n",
    "            self.experience.append(hx)\n",
    "            \n",
    "    def reset_her(self):\n",
    "        self.her_experience = [] # deque(maxlen=memory_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning_HERQ:\n",
    "    \n",
    "    def __init__(self, o_space, a_space, buffer, lr, n_step):\n",
    "        self.n_step = n_step\n",
    "        self.a_space = a_space\n",
    "        self.buffer = buffer\n",
    "        self.lr = lr\n",
    "        self.experience = deque(maxlen=memory_cap)\n",
    "        self.her_experience = deque(maxlen=memory_cap)\n",
    "        \n",
    "        self.clf = Sequential()\n",
    "        self.clf.add(Dense(64, input_shape=(o_space,), activation=\"relu\"))\n",
    "        self.clf.add(Dense(64, activation=\"relu\"))\n",
    "        self.clf.add(Dense(self.a_space, activation=\"linear\"))\n",
    "        self.clf.compile(loss=\"mse\", optimizer=Adam(lr=lr))\n",
    "        \n",
    "    def add_experience(self, s, a, r, s_next, terminal):\n",
    "        self.experience.append([s, a, r, s, terminal])\n",
    "        \n",
    "    def add_her_experience(self, s, a, r, s_next, terminal):\n",
    "        self.her_experience.append([s, a, r, s, terminal])\n",
    "        \n",
    "    def get_action(self, s):\n",
    "        random_explore = np.random.rand()\n",
    "        \n",
    "        if random_explore < epsilon:\n",
    "            return random.randrange(self.a_space)\n",
    "        \n",
    "        q_vals = self.clf.predict(s)\n",
    "        \n",
    "        return np.argmax(q_vals[0])\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        min_buffer_len = np.min([len(self.experience), self.buffer])\n",
    "        \n",
    "        exp_batch = random.sample(self.experience, min_buffer_len)\n",
    "        \n",
    "        for s, a, r, s_next, terminal in exp_batch:\n",
    "            q_update = r\n",
    "            \n",
    "            if not terminal:\n",
    "                q_update = (r + discount * np.amax(self.clf.predict(s_next)[0]))\n",
    "            \n",
    "            q_vals = self.clf.predict(s)\n",
    "            q_vals[0][a] = q_update\n",
    "            self.clf.fit(s, q_vals, verbose=0)\n",
    "            \n",
    "    def modify_her_list(self):\n",
    "        new_her_experience = copy.deepcopy(self.her_experience)\n",
    "        new_her_len = len(new_her_experience)\n",
    "        her_goal = self.her_experience[-1][3]\n",
    "        \n",
    "        for i in range(new_her_len):\n",
    "            new_her_experience[-1-i][0] = her_goal\n",
    "            new_her_experience[-1-i][2] = -1.0\n",
    "            new_her_experience[-1-i][3] = her_goal\n",
    "            new_her_experience[-1-i][4] = False\n",
    "            \n",
    "            if (np.sum(np.abs((new_her_experience[-1-i][4] - her_goal))) == 0):\n",
    "                new_her_experience[-1-i][2] = 0.0\n",
    "                new_her_experience[-1-i][4] = True\n",
    "        \n",
    "        for hx in new_her_experience:\n",
    "            self.experience.append(hx)\n",
    "            \n",
    "    def reset_her(self):\n",
    "        self.her_experience = deque(maxlen=memory_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Learning_Simple:\n",
    "    \n",
    "    def __init__(self, o_space, a_space, buffer, lr, n_step, state_shape):\n",
    "        self.n_step = n_step\n",
    "        self.a_space = a_space\n",
    "        self.buffer = buffer\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.memory_cap = memory_cap\n",
    "        self.st_idx = 0\n",
    "        self.memory_size = 0\n",
    "        \n",
    "        print(state_shape)\n",
    "        \n",
    "        state_list_shape = [self.memory_cap] + list(state_shape)\n",
    "        \n",
    "        self.s = np.zeros(state_list_shape, dtype=float)\n",
    "        self.a = np.zeros(memory_cap, dtype=int)\n",
    "        self.r = np.zeros(memory_cap, dtype=float)\n",
    "        self.s_next = np.zeros(state_list_shape, dtype=float)\n",
    "        self.terminal = np.zeros(memory_cap, dtype=bool)\n",
    "        \n",
    "        print(self.s)\n",
    "        print(self.a)\n",
    "        print(self.r)\n",
    "        print(self.s_next)\n",
    "        print(self.terminal)\n",
    "                \n",
    "        self.clf = Sequential()\n",
    "        self.clf.add(Dense(64, input_shape=state_shape, activation=\"relu\"))\n",
    "        self.clf.add(Dense(64, activation=\"relu\"))\n",
    "        self.clf.add(Dense(self.a_space, activation=\"linear\"))\n",
    "        self.clf.compile(loss=\"mse\", optimizer=Adam(lr=lr))\n",
    "        \n",
    "    def add_experience(self, s, a, r, s_next, terminal):\n",
    "        self.s[self.st_idx] = s\n",
    "        self.a[self.st_idx] = a\n",
    "        self.r[self.st_idx] = r\n",
    "        self.s_next[self.st_idx] = s_next\n",
    "        self.terminal[self.st_idx] = terminal\n",
    "        \n",
    "        if self.memory_size < self.memory_cap:\n",
    "            self.memory_size += 1\n",
    "            \n",
    "        self.st_idx += 1\n",
    "        \n",
    "        if self.st_idx >= self.memory_cap:\n",
    "            self.st_idx = 0 # resetting at 0\n",
    "        \n",
    "    def get_action(self, s):\n",
    "        random_explore = np.random.rand()\n",
    "        \n",
    "        if random_explore < epsilon:\n",
    "            return random.randrange(self.a_space)\n",
    "        \n",
    "        q_vals = self.clf.predict(s)\n",
    "        \n",
    "        return np.argmax(q_vals[0])\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        \n",
    "#         print(self.experience)\n",
    "#         exp_np = np.array(self.experience)\n",
    "#         print(type(exp_np))\n",
    "#         print(exp_np)\n",
    "        \n",
    "        time_a = time.time()\n",
    "        min_buffer_len = np.min([self.memory_size, self.buffer])\n",
    "#         print(\"min buffer\", min_buffer_len)\n",
    "        time_b = time.time()\n",
    "#         exp_batch = random.sample(exp_np, min_buffer_len)\n",
    "#         print(exp_batch)\n",
    "#         print(0, len(self.experience), min_buffer_len)\n",
    "        idx = np.random.randint(low=0, high=self.memory_size, size=min_buffer_len, dtype=int)\n",
    "#         print(idx)\n",
    "#         print(exp_np)\n",
    "        s_batch = self.s[idx]\n",
    "        a_batch = self.a[idx]\n",
    "        r_batch = self.r[idx]\n",
    "        s_next_batch = self.s_next[idx]\n",
    "        terminal_batch = self.terminal[idx]\n",
    "        \n",
    "        time_c = time.time()\n",
    "        \n",
    "#         print(\"s_batch 1 shape\", s_batch)\n",
    "\n",
    "        for i in range(len(s_batch)):\n",
    "            s = np.array([s_batch[i]])\n",
    "            a = a_batch[i]\n",
    "            r = r_batch[i]\n",
    "            s_next = np.array([s_next_batch[i]])\n",
    "            terminal = terminal_batch[i]\n",
    "            \n",
    "#             print(s)\n",
    "#             print(s_next)\n",
    "        \n",
    "            q_update = r\n",
    "            \n",
    "#             s_next\n",
    "            \n",
    "#             print(\"s_next\", s_next)\n",
    "#             print(\"s_next shape\", s_next.shape)\n",
    "            \n",
    "            if not terminal:\n",
    "                q_update = (r + discount * np.amax(self.clf.predict(s_next)[0]))\n",
    "            \n",
    "            q_vals = self.clf.predict(s)\n",
    "            q_vals[0][a] = q_update\n",
    "#             print(type(q_vals))\n",
    "#             print(type(s))\n",
    "            self.clf.fit(s, q_vals, verbose=0)\n",
    "            \n",
    "        time_d = time.time()\n",
    "        \n",
    "        a_perc = (time_b - time_a) / (time_d - time_a)\n",
    "        b_perc = (time_c - time_b) / (time_d - time_a)\n",
    "        c_perc = (time_d - time_c) / (time_d - time_a)\n",
    "#         d_perc = (time_e - time_d) / (time_e - time_a)\n",
    "\n",
    "#         print(\"a\", a_perc*100)\n",
    "#         print(\"b\", b_perc*100)\n",
    "#         print(\"c\", c_perc*100)\n",
    "#         print(\"d\", d_perc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rates = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "# buffers = [50, 100, 250, 500]\n",
    "# methods = ['sarsa', 'exp_sarsa', 'q']\n",
    "# seeds = np.arange(20)\n",
    "\n",
    "# max_episodes = 100\n",
    "\n",
    "# more doable (recommended by Veronica)\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "buffers = [50, 100, 250, 500]\n",
    "methods = ['sarsa', 'exp_sarsa', 'q']\n",
    "seeds = np.arange(5)\n",
    "max_episodes = 100\n",
    "\n",
    "# learning_rates = [0.1, 0.01, 0.001]\n",
    "# learning_rates = [0.1, 0.01]\n",
    "# buffers = [50]\n",
    "# methods = ['exp_sarsa']\n",
    "# seeds = np.arange(1)\n",
    "\n",
    "# max_episodes = 25\n",
    "\n",
    "n_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 50\n",
    "lr = 0.01\n",
    "seed = 0\n",
    "n_step = 1\n",
    "\n",
    "\n",
    "max_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.01 0\n",
      "(4,)\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[False False False ... False False False]\n",
      "num_episode: 1; terminal_step: 31\n",
      "num_episode: 2; terminal_step: 8\n",
      "num_episode: 3; terminal_step: 9\n",
      "num_episode: 4; terminal_step: 9\n",
      "num_episode: 5; terminal_step: 13\n",
      "num_episode: 6; terminal_step: 10\n",
      "num_episode: 7; terminal_step: 11\n",
      "num_episode: 8; terminal_step: 10\n",
      "num_episode: 9; terminal_step: 11\n",
      "num_episode: 10; terminal_step: 11\n",
      "num_episode: 11; terminal_step: 99\n",
      "num_episode: 12; terminal_step: 120\n",
      "num_episode: 13; terminal_step: 16\n",
      "num_episode: 14; terminal_step: 84\n",
      "num_episode: 15; terminal_step: 12\n",
      "num_episode: 16; terminal_step: 14\n",
      "num_episode: 17; terminal_step: 9\n",
      "num_episode: 18; terminal_step: 14\n",
      "num_episode: 19; terminal_step: 9\n",
      "num_episode: 20; terminal_step: 35\n",
      "num_episode: 21; terminal_step: 51\n",
      "num_episode: 22; terminal_step: 41\n",
      "num_episode: 23; terminal_step: 9\n",
      "num_episode: 24; terminal_step: 65\n",
      "num_episode: 25; terminal_step: 11\n",
      "num_episode: 26; terminal_step: 12\n",
      "num_episode: 27; terminal_step: 16\n",
      "num_episode: 28; terminal_step: 33\n",
      "num_episode: 29; terminal_step: 103\n",
      "num_episode: 30; terminal_step: 50\n",
      "num_episode: 31; terminal_step: 17\n",
      "num_episode: 32; terminal_step: 11\n",
      "num_episode: 33; terminal_step: 18\n",
      "num_episode: 34; terminal_step: 30\n",
      "num_episode: 35; terminal_step: 10\n",
      "num_episode: 36; terminal_step: 9\n",
      "num_episode: 37; terminal_step: 12\n",
      "num_episode: 38; terminal_step: 18\n",
      "num_episode: 39; terminal_step: 18\n",
      "num_episode: 40; terminal_step: 24\n",
      "num_episode: 41; terminal_step: 59\n",
      "num_episode: 42; terminal_step: 32\n",
      "num_episode: 43; terminal_step: 19\n",
      "num_episode: 44; terminal_step: 11\n",
      "num_episode: 45; terminal_step: 13\n",
      "num_episode: 46; terminal_step: 21\n",
      "num_episode: 47; terminal_step: 25\n",
      "num_episode: 48; terminal_step: 17\n",
      "num_episode: 49; terminal_step: 17\n",
      "num_episode: 50; terminal_step: 20\n",
      "num_episode: 51; terminal_step: 15\n",
      "num_episode: 52; terminal_step: 20\n",
      "num_episode: 53; terminal_step: 16\n",
      "num_episode: 54; terminal_step: 9\n",
      "num_episode: 55; terminal_step: 12\n",
      "num_episode: 56; terminal_step: 42\n",
      "num_episode: 57; terminal_step: 12\n",
      "num_episode: 58; terminal_step: 47\n",
      "num_episode: 59; terminal_step: 38\n",
      "num_episode: 60; terminal_step: 26\n",
      "num_episode: 61; terminal_step: 29\n",
      "num_episode: 62; terminal_step: 29\n",
      "num_episode: 63; terminal_step: 16\n",
      "num_episode: 64; terminal_step: 19\n",
      "num_episode: 65; terminal_step: 12\n",
      "num_episode: 66; terminal_step: 26\n",
      "num_episode: 67; terminal_step: 34\n",
      "num_episode: 68; terminal_step: 58\n",
      "num_episode: 69; terminal_step: 33\n",
      "num_episode: 70; terminal_step: 22\n",
      "num_episode: 71; terminal_step: 35\n",
      "num_episode: 72; terminal_step: 40\n",
      "num_episode: 73; terminal_step: 32\n",
      "num_episode: 74; terminal_step: 25\n",
      "num_episode: 75; terminal_step: 43\n",
      "num_episode: 76; terminal_step: 88\n",
      "num_episode: 77; terminal_step: 26\n",
      "num_episode: 78; terminal_step: 136\n",
      "num_episode: 79; terminal_step: 36\n",
      "num_episode: 80; terminal_step: 32\n",
      "num_episode: 81; terminal_step: 76\n",
      "num_episode: 82; terminal_step: 125\n",
      "num_episode: 83; terminal_step: 51\n",
      "num_episode: 84; terminal_step: 174\n",
      "num_episode: 85; terminal_step: 50\n",
      "num_episode: 86; terminal_step: 16\n",
      "num_episode: 87; terminal_step: 12\n",
      "num_episode: 88; terminal_step: 16\n",
      "num_episode: 89; terminal_step: 215\n",
      "num_episode: 90; terminal_step: 17\n",
      "num_episode: 91; terminal_step: 270\n",
      "num_episode: 92; terminal_step: 268\n",
      "num_episode: 93; terminal_step: 96\n",
      "num_episode: 94; terminal_step: 229\n",
      "num_episode: 95; terminal_step: 140\n",
      "num_episode: 96; terminal_step: 51\n",
      "num_episode: 97; terminal_step: 446\n",
      "num_episode: 98; terminal_step: 89\n",
      "num_episode: 99; terminal_step: 142\n",
      "num_episode: 100; terminal_step: 132\n",
      "num_episode: 101; terminal_step: 62\n",
      "num_episode: 102; terminal_step: 126\n",
      "num_episode: 103; terminal_step: 317\n",
      "num_episode: 104; terminal_step: 89\n",
      "num_episode: 105; terminal_step: 204\n",
      "num_episode: 106; terminal_step: 89\n",
      "num_episode: 107; terminal_step: 135\n",
      "num_episode: 108; terminal_step: 152\n",
      "num_episode: 109; terminal_step: 500\n",
      "num_episode: 110; terminal_step: 10\n",
      "num_episode: 111; terminal_step: 10\n",
      "num_episode: 112; terminal_step: 11\n",
      "num_episode: 113; terminal_step: 11\n",
      "num_episode: 114; terminal_step: 172\n",
      "num_episode: 115; terminal_step: 16\n",
      "num_episode: 116; terminal_step: 16\n",
      "num_episode: 117; terminal_step: 20\n",
      "num_episode: 118; terminal_step: 13\n",
      "num_episode: 119; terminal_step: 52\n",
      "num_episode: 120; terminal_step: 14\n",
      "num_episode: 121; terminal_step: 121\n",
      "num_episode: 122; terminal_step: 49\n",
      "num_episode: 123; terminal_step: 19\n",
      "num_episode: 124; terminal_step: 119\n",
      "num_episode: 125; terminal_step: 57\n",
      "num_episode: 126; terminal_step: 34\n",
      "num_episode: 127; terminal_step: 10\n",
      "num_episode: 128; terminal_step: 36\n",
      "num_episode: 129; terminal_step: 33\n",
      "num_episode: 130; terminal_step: 14\n",
      "num_episode: 131; terminal_step: 118\n",
      "num_episode: 132; terminal_step: 500\n",
      "num_episode: 133; terminal_step: 121\n",
      "num_episode: 134; terminal_step: 214\n",
      "num_episode: 135; terminal_step: 155\n",
      "num_episode: 136; terminal_step: 125\n",
      "num_episode: 137; terminal_step: 10\n",
      "num_episode: 138; terminal_step: 387\n",
      "num_episode: 139; terminal_step: 147\n",
      "num_episode: 140; terminal_step: 43\n",
      "num_episode: 141; terminal_step: 11\n",
      "num_episode: 142; terminal_step: 24\n",
      "num_episode: 143; terminal_step: 11\n",
      "num_episode: 144; terminal_step: 92\n",
      "num_episode: 145; terminal_step: 87\n",
      "num_episode: 146; terminal_step: 132\n",
      "num_episode: 147; terminal_step: 134\n",
      "num_episode: 148; terminal_step: 108\n",
      "num_episode: 149; terminal_step: 9\n",
      "num_episode: 150; terminal_step: 9\n",
      "num_episode: 151; terminal_step: 10\n",
      "num_episode: 152; terminal_step: 29\n",
      "num_episode: 153; terminal_step: 10\n",
      "num_episode: 154; terminal_step: 11\n",
      "num_episode: 155; terminal_step: 24\n",
      "num_episode: 156; terminal_step: 12\n",
      "num_episode: 157; terminal_step: 132\n",
      "num_episode: 158; terminal_step: 382\n",
      "num_episode: 159; terminal_step: 500\n",
      "num_episode: 160; terminal_step: 124\n",
      "num_episode: 161; terminal_step: 96\n",
      "num_episode: 162; terminal_step: 12\n",
      "num_episode: 163; terminal_step: 11\n",
      "num_episode: 164; terminal_step: 13\n",
      "num_episode: 165; terminal_step: 18\n",
      "num_episode: 166; terminal_step: 26\n",
      "num_episode: 167; terminal_step: 10\n",
      "num_episode: 168; terminal_step: 10\n",
      "num_episode: 169; terminal_step: 9\n",
      "num_episode: 170; terminal_step: 9\n",
      "num_episode: 171; terminal_step: 24\n",
      "num_episode: 172; terminal_step: 16\n",
      "num_episode: 173; terminal_step: 112\n",
      "num_episode: 174; terminal_step: 337\n",
      "num_episode: 175; terminal_step: 161\n",
      "num_episode: 176; terminal_step: 187\n",
      "num_episode: 177; terminal_step: 338\n",
      "num_episode: 178; terminal_step: 108\n",
      "num_episode: 179; terminal_step: 11\n",
      "num_episode: 180; terminal_step: 500\n",
      "num_episode: 181; terminal_step: 329\n",
      "num_episode: 182; terminal_step: 10\n",
      "num_episode: 183; terminal_step: 15\n",
      "num_episode: 184; terminal_step: 113\n",
      "num_episode: 185; terminal_step: 500\n",
      "num_episode: 186; terminal_step: 9\n",
      "num_episode: 187; terminal_step: 500\n",
      "num_episode: 188; terminal_step: 500\n",
      "num_episode: 189; terminal_step: 128\n",
      "num_episode: 190; terminal_step: 255\n",
      "num_episode: 191; terminal_step: 127\n",
      "num_episode: 192; terminal_step: 332\n",
      "num_episode: 193; terminal_step: 141\n",
      "num_episode: 194; terminal_step: 123\n",
      "num_episode: 195; terminal_step: 114\n",
      "num_episode: 196; terminal_step: 281\n",
      "num_episode: 197; terminal_step: 209\n",
      "num_episode: 198; terminal_step: 370\n",
      "num_episode: 199; terminal_step: 128\n",
      "num_episode: 200; terminal_step: 392\n",
      "num_episode: 201; terminal_step: 210\n",
      "num_episode: 202; terminal_step: 71\n",
      "num_episode: 203; terminal_step: 103\n",
      "num_episode: 204; terminal_step: 129\n",
      "num_episode: 205; terminal_step: 113\n",
      "num_episode: 206; terminal_step: 11\n",
      "num_episode: 207; terminal_step: 19\n",
      "num_episode: 208; terminal_step: 106\n",
      "num_episode: 209; terminal_step: 500\n",
      "num_episode: 210; terminal_step: 128\n",
      "num_episode: 211; terminal_step: 500\n",
      "num_episode: 212; terminal_step: 345\n",
      "num_episode: 213; terminal_step: 247\n",
      "num_episode: 214; terminal_step: 14\n",
      "num_episode: 215; terminal_step: 112\n",
      "num_episode: 216; terminal_step: 82\n",
      "num_episode: 217; terminal_step: 9\n",
      "num_episode: 218; terminal_step: 79\n",
      "num_episode: 219; terminal_step: 121\n",
      "num_episode: 220; terminal_step: 202\n",
      "num_episode: 221; terminal_step: 168\n",
      "num_episode: 222; terminal_step: 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episode: 223; terminal_step: 64\n",
      "num_episode: 224; terminal_step: 179\n",
      "num_episode: 225; terminal_step: 119\n",
      "num_episode: 226; terminal_step: 222\n",
      "num_episode: 227; terminal_step: 119\n",
      "num_episode: 228; terminal_step: 438\n",
      "num_episode: 229; terminal_step: 155\n",
      "num_episode: 230; terminal_step: 136\n",
      "num_episode: 231; terminal_step: 172\n",
      "num_episode: 232; terminal_step: 170\n",
      "num_episode: 233; terminal_step: 13\n",
      "num_episode: 234; terminal_step: 75\n",
      "num_episode: 235; terminal_step: 10\n",
      "num_episode: 236; terminal_step: 11\n",
      "num_episode: 237; terminal_step: 85\n",
      "num_episode: 238; terminal_step: 381\n",
      "num_episode: 239; terminal_step: 176\n",
      "num_episode: 240; terminal_step: 224\n",
      "num_episode: 241; terminal_step: 9\n",
      "num_episode: 242; terminal_step: 126\n",
      "num_episode: 243; terminal_step: 500\n",
      "num_episode: 244; terminal_step: 215\n",
      "num_episode: 245; terminal_step: 85\n",
      "num_episode: 246; terminal_step: 306\n",
      "num_episode: 247; terminal_step: 163\n",
      "num_episode: 248; terminal_step: 214\n",
      "num_episode: 249; terminal_step: 127\n",
      "num_episode: 250; terminal_step: 140\n",
      "CPU times: user 1min 7s, sys: 11.1 s, total: 1min 18s\n",
      "Wall time: 56.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_episodes = 250\n",
    "\n",
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('CartPole-v1')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_Simple(o_space, a_space, buffer, lr, n_step, env.observation_space.shape)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    start = time.time()\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "        \n",
    "        time_a = time.time()\n",
    "        a = clf.get_action(s)\n",
    "        \n",
    "        time_b = time.time()\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        time_c = time.time()\n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "        \n",
    "        time_d = time.time()\n",
    "#         clf.experience_replay()\n",
    "        time_e = time.time()\n",
    "    \n",
    "    clf.experience_replay()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         a_perc = (time_b - time_a) / (time_e - time_a)\n",
    "#         b_perc = (time_c - time_b) / (time_e - time_a)\n",
    "#         c_perc = (time_d - time_c) / (time_e - time_a)\n",
    "#         d_perc = (time_e - time_d) / (time_e - time_a)\n",
    "\n",
    "#         print(\"a\", a_perc*100)\n",
    "#         print(\"b\", b_perc*100)\n",
    "#         print(\"c\", c_perc*100)\n",
    "#         print(\"d\", d_perc*100)\n",
    "        \n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    \n",
    "#     print(\"elapsed\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('CartPole-v1')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_HER(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    start = time.time()\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "    clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "        clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "        clf.experience_replay()\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('CartPole-v1')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_HERQ(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    start = time.time()\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "    clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "        clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "        clf.experience_replay()\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.01 0\n",
      "num_episode: 1; terminal_step: 10\n",
      "0.907524824142456\n",
      "num_episode: 2; terminal_step: 15\n",
      "0.5968668460845947\n",
      "num_episode: 3; terminal_step: 14\n",
      "0.8050639629364014\n",
      "num_episode: 4; terminal_step: 9\n",
      "0.6469621658325195\n",
      "num_episode: 5; terminal_step: 11\n",
      "0.9324600696563721\n",
      "num_episode: 6; terminal_step: 17\n",
      "1.466541051864624\n",
      "num_episode: 7; terminal_step: 8\n",
      "0.6855208873748779\n",
      "num_episode: 8; terminal_step: 34\n",
      "3.120595932006836\n",
      "num_episode: 9; terminal_step: 9\n",
      "0.7865400314331055\n",
      "num_episode: 10; terminal_step: 17\n",
      "1.616866111755371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-575080fce933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-17227fbe0e3a>\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mq_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mq_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mq_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1835\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m-> 1100\u001b[0;31m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[0m\u001b[1;32m   1101\u001b[0m             raise ValueError(\n\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/mlp3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mndims\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('CartPole-v1')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_HER(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    start = time.time()\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "    clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "        clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "        clf.experience_replay()\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.01 0\n",
      "num_episode: 1; terminal_step: 10\n",
      "num_episode: 2; terminal_step: 10\n",
      "num_episode: 3; terminal_step: 15\n",
      "num_episode: 4; terminal_step: 20\n",
      "num_episode: 5; terminal_step: 26\n",
      "num_episode: 6; terminal_step: 62\n",
      "num_episode: 7; terminal_step: 14\n",
      "num_episode: 8; terminal_step: 27\n",
      "num_episode: 9; terminal_step: 26\n",
      "num_episode: 10; terminal_step: 26\n",
      "num_episode: 11; terminal_step: 13\n",
      "num_episode: 12; terminal_step: 13\n",
      "num_episode: 13; terminal_step: 39\n",
      "num_episode: 14; terminal_step: 25\n",
      "num_episode: 15; terminal_step: 16\n",
      "num_episode: 16; terminal_step: 36\n",
      "num_episode: 17; terminal_step: 21\n",
      "num_episode: 18; terminal_step: 11\n",
      "num_episode: 19; terminal_step: 23\n",
      "num_episode: 20; terminal_step: 45\n",
      "num_episode: 21; terminal_step: 48\n",
      "num_episode: 22; terminal_step: 50\n",
      "num_episode: 23; terminal_step: 13\n",
      "num_episode: 24; terminal_step: 28\n",
      "num_episode: 25; terminal_step: 21\n",
      "num_episode: 26; terminal_step: 11\n",
      "num_episode: 27; terminal_step: 9\n",
      "num_episode: 28; terminal_step: 60\n",
      "num_episode: 29; terminal_step: 38\n",
      "num_episode: 30; terminal_step: 16\n",
      "num_episode: 31; terminal_step: 19\n",
      "num_episode: 32; terminal_step: 13\n",
      "num_episode: 33; terminal_step: 12\n",
      "num_episode: 34; terminal_step: 17\n",
      "num_episode: 35; terminal_step: 16\n",
      "num_episode: 36; terminal_step: 17\n",
      "num_episode: 37; terminal_step: 13\n",
      "num_episode: 38; terminal_step: 25\n",
      "num_episode: 39; terminal_step: 33\n",
      "num_episode: 40; terminal_step: 27\n",
      "num_episode: 41; terminal_step: 13\n",
      "num_episode: 42; terminal_step: 19\n",
      "num_episode: 43; terminal_step: 48\n",
      "num_episode: 44; terminal_step: 21\n",
      "num_episode: 45; terminal_step: 23\n",
      "num_episode: 46; terminal_step: 39\n",
      "num_episode: 47; terminal_step: 15\n",
      "num_episode: 48; terminal_step: 20\n",
      "num_episode: 49; terminal_step: 15\n",
      "num_episode: 50; terminal_step: 21\n",
      "num_episode: 51; terminal_step: 38\n",
      "num_episode: 52; terminal_step: 54\n",
      "num_episode: 53; terminal_step: 12\n",
      "num_episode: 54; terminal_step: 42\n",
      "num_episode: 55; terminal_step: 12\n",
      "num_episode: 56; terminal_step: 21\n",
      "num_episode: 57; terminal_step: 22\n",
      "num_episode: 58; terminal_step: 12\n",
      "num_episode: 59; terminal_step: 25\n",
      "num_episode: 60; terminal_step: 18\n",
      "num_episode: 61; terminal_step: 16\n",
      "num_episode: 62; terminal_step: 18\n",
      "num_episode: 63; terminal_step: 21\n",
      "num_episode: 64; terminal_step: 8\n",
      "num_episode: 65; terminal_step: 32\n",
      "num_episode: 66; terminal_step: 22\n",
      "num_episode: 67; terminal_step: 20\n",
      "num_episode: 68; terminal_step: 14\n",
      "num_episode: 69; terminal_step: 10\n",
      "num_episode: 70; terminal_step: 30\n",
      "num_episode: 71; terminal_step: 18\n",
      "num_episode: 72; terminal_step: 27\n",
      "num_episode: 73; terminal_step: 10\n",
      "num_episode: 74; terminal_step: 12\n",
      "num_episode: 75; terminal_step: 38\n",
      "num_episode: 76; terminal_step: 20\n",
      "num_episode: 77; terminal_step: 12\n",
      "num_episode: 78; terminal_step: 22\n",
      "num_episode: 79; terminal_step: 16\n",
      "num_episode: 80; terminal_step: 13\n",
      "num_episode: 81; terminal_step: 15\n",
      "num_episode: 82; terminal_step: 13\n",
      "num_episode: 83; terminal_step: 22\n",
      "num_episode: 84; terminal_step: 51\n",
      "num_episode: 85; terminal_step: 24\n",
      "num_episode: 86; terminal_step: 20\n",
      "num_episode: 87; terminal_step: 20\n",
      "num_episode: 88; terminal_step: 16\n",
      "num_episode: 89; terminal_step: 17\n",
      "num_episode: 90; terminal_step: 13\n",
      "num_episode: 91; terminal_step: 28\n",
      "num_episode: 92; terminal_step: 11\n",
      "num_episode: 93; terminal_step: 15\n",
      "num_episode: 94; terminal_step: 12\n",
      "num_episode: 95; terminal_step: 18\n",
      "num_episode: 96; terminal_step: 30\n",
      "num_episode: 97; terminal_step: 21\n",
      "num_episode: 98; terminal_step: 63\n",
      "num_episode: 99; terminal_step: 18\n",
      "num_episode: 100; terminal_step: 18\n"
     ]
    }
   ],
   "source": [
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('CartPole-v1')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_HER(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "    clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "        clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "        clf.experience_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 10,\n",
       " 15,\n",
       " 20,\n",
       " 26,\n",
       " 62,\n",
       " 14,\n",
       " 27,\n",
       " 26,\n",
       " 26,\n",
       " 13,\n",
       " 13,\n",
       " 39,\n",
       " 25,\n",
       " 16,\n",
       " 36,\n",
       " 21,\n",
       " 11,\n",
       " 23,\n",
       " 45,\n",
       " 48,\n",
       " 50,\n",
       " 13,\n",
       " 28,\n",
       " 21,\n",
       " 11,\n",
       " 9,\n",
       " 60,\n",
       " 38,\n",
       " 16,\n",
       " 19,\n",
       " 13,\n",
       " 12,\n",
       " 17,\n",
       " 16,\n",
       " 17,\n",
       " 13,\n",
       " 25,\n",
       " 33,\n",
       " 27,\n",
       " 13,\n",
       " 19,\n",
       " 48,\n",
       " 21,\n",
       " 23,\n",
       " 39,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 21,\n",
       " 38,\n",
       " 54,\n",
       " 12,\n",
       " 42,\n",
       " 12,\n",
       " 21,\n",
       " 22,\n",
       " 12,\n",
       " 25,\n",
       " 18,\n",
       " 16,\n",
       " 18,\n",
       " 21,\n",
       " 8,\n",
       " 32,\n",
       " 22,\n",
       " 20,\n",
       " 14,\n",
       " 10,\n",
       " 30,\n",
       " 18,\n",
       " 27,\n",
       " 10,\n",
       " 12,\n",
       " 38,\n",
       " 20,\n",
       " 12,\n",
       " 22,\n",
       " 16,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 22,\n",
       " 51,\n",
       " 24,\n",
       " 20,\n",
       " 20,\n",
       " 16,\n",
       " 17,\n",
       " 13,\n",
       " 28,\n",
       " 11,\n",
       " 15,\n",
       " 12,\n",
       " 18,\n",
       " 30,\n",
       " 21,\n",
       " 63,\n",
       " 18,\n",
       " 18]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.01 0\n",
      "num_episode: 1; terminal_step: 34\n",
      "num_episode: 2; terminal_step: 102\n",
      "num_episode: 3; terminal_step: 8\n",
      "num_episode: 4; terminal_step: 11\n",
      "num_episode: 5; terminal_step: 10\n",
      "num_episode: 6; terminal_step: 10\n",
      "num_episode: 7; terminal_step: 23\n",
      "num_episode: 8; terminal_step: 10\n",
      "num_episode: 9; terminal_step: 12\n",
      "num_episode: 10; terminal_step: 10\n",
      "num_episode: 11; terminal_step: 124\n",
      "num_episode: 12; terminal_step: 10\n",
      "num_episode: 13; terminal_step: 9\n",
      "num_episode: 14; terminal_step: 10\n",
      "num_episode: 15; terminal_step: 9\n",
      "num_episode: 16; terminal_step: 9\n",
      "num_episode: 17; terminal_step: 9\n",
      "num_episode: 18; terminal_step: 11\n",
      "num_episode: 19; terminal_step: 12\n",
      "num_episode: 20; terminal_step: 18\n",
      "num_episode: 21; terminal_step: 13\n",
      "num_episode: 22; terminal_step: 15\n",
      "num_episode: 23; terminal_step: 16\n",
      "num_episode: 24; terminal_step: 23\n",
      "num_episode: 25; terminal_step: 60\n",
      "num_episode: 26; terminal_step: 30\n",
      "num_episode: 27; terminal_step: 22\n",
      "num_episode: 28; terminal_step: 26\n",
      "num_episode: 29; terminal_step: 9\n",
      "num_episode: 30; terminal_step: 23\n",
      "num_episode: 31; terminal_step: 20\n",
      "num_episode: 32; terminal_step: 34\n",
      "num_episode: 33; terminal_step: 46\n",
      "num_episode: 34; terminal_step: 144\n",
      "num_episode: 35; terminal_step: 31\n",
      "num_episode: 36; terminal_step: 67\n",
      "num_episode: 37; terminal_step: 22\n",
      "num_episode: 38; terminal_step: 55\n",
      "num_episode: 39; terminal_step: 37\n",
      "num_episode: 40; terminal_step: 95\n",
      "num_episode: 41; terminal_step: 55\n",
      "num_episode: 42; terminal_step: 63\n",
      "num_episode: 43; terminal_step: 50\n",
      "num_episode: 44; terminal_step: 89\n",
      "num_episode: 45; terminal_step: 98\n",
      "num_episode: 46; terminal_step: 15\n",
      "num_episode: 47; terminal_step: 14\n",
      "num_episode: 48; terminal_step: 12\n",
      "num_episode: 49; terminal_step: 9\n",
      "num_episode: 50; terminal_step: 48\n",
      "num_episode: 51; terminal_step: 85\n",
      "num_episode: 52; terminal_step: 85\n",
      "num_episode: 53; terminal_step: 127\n",
      "num_episode: 54; terminal_step: 31\n",
      "num_episode: 55; terminal_step: 24\n",
      "num_episode: 56; terminal_step: 32\n",
      "num_episode: 57; terminal_step: 36\n",
      "num_episode: 58; terminal_step: 51\n",
      "num_episode: 59; terminal_step: 13\n",
      "num_episode: 60; terminal_step: 49\n",
      "num_episode: 61; terminal_step: 47\n",
      "num_episode: 62; terminal_step: 53\n",
      "num_episode: 63; terminal_step: 50\n",
      "num_episode: 64; terminal_step: 74\n",
      "num_episode: 65; terminal_step: 183\n",
      "num_episode: 66; terminal_step: 161\n",
      "num_episode: 67; terminal_step: 53\n",
      "num_episode: 68; terminal_step: 87\n",
      "num_episode: 69; terminal_step: 71\n",
      "num_episode: 70; terminal_step: 15\n",
      "num_episode: 71; terminal_step: 54\n",
      "num_episode: 72; terminal_step: 48\n",
      "num_episode: 73; terminal_step: 140\n",
      "num_episode: 74; terminal_step: 19\n",
      "num_episode: 75; terminal_step: 41\n",
      "num_episode: 76; terminal_step: 31\n",
      "num_episode: 77; terminal_step: 32\n",
      "num_episode: 78; terminal_step: 25\n",
      "num_episode: 79; terminal_step: 38\n",
      "num_episode: 80; terminal_step: 76\n",
      "num_episode: 81; terminal_step: 63\n",
      "num_episode: 82; terminal_step: 68\n",
      "num_episode: 83; terminal_step: 77\n",
      "num_episode: 84; terminal_step: 226\n",
      "num_episode: 85; terminal_step: 153\n",
      "num_episode: 86; terminal_step: 157\n",
      "num_episode: 87; terminal_step: 94\n",
      "num_episode: 88; terminal_step: 202\n",
      "num_episode: 89; terminal_step: 168\n",
      "num_episode: 90; terminal_step: 138\n",
      "num_episode: 91; terminal_step: 62\n",
      "num_episode: 92; terminal_step: 61\n",
      "num_episode: 93; terminal_step: 500\n",
      "num_episode: 94; terminal_step: 276\n",
      "num_episode: 95; terminal_step: 154\n",
      "num_episode: 96; terminal_step: 343\n",
      "num_episode: 97; terminal_step: 174\n",
      "num_episode: 98; terminal_step: 268\n",
      "num_episode: 99; terminal_step: 229\n",
      "num_episode: 100; terminal_step: 265\n",
      "num_episode: 101; terminal_step: 500\n",
      "num_episode: 102; terminal_step: 77\n",
      "num_episode: 103; terminal_step: 122\n",
      "num_episode: 104; terminal_step: 27\n",
      "num_episode: 105; terminal_step: 28\n",
      "num_episode: 106; terminal_step: 154\n",
      "num_episode: 107; terminal_step: 204\n",
      "num_episode: 108; terminal_step: 164\n",
      "num_episode: 109; terminal_step: 51\n",
      "num_episode: 110; terminal_step: 23\n",
      "num_episode: 111; terminal_step: 80\n",
      "num_episode: 112; terminal_step: 92\n",
      "num_episode: 113; terminal_step: 210\n",
      "num_episode: 114; terminal_step: 30\n",
      "num_episode: 115; terminal_step: 92\n",
      "num_episode: 116; terminal_step: 93\n",
      "num_episode: 117; terminal_step: 91\n",
      "num_episode: 118; terminal_step: 171\n",
      "num_episode: 119; terminal_step: 64\n",
      "num_episode: 120; terminal_step: 50\n",
      "num_episode: 121; terminal_step: 10\n",
      "num_episode: 122; terminal_step: 9\n",
      "num_episode: 123; terminal_step: 23\n",
      "num_episode: 124; terminal_step: 24\n",
      "num_episode: 125; terminal_step: 91\n",
      "num_episode: 126; terminal_step: 156\n",
      "num_episode: 127; terminal_step: 58\n",
      "num_episode: 128; terminal_step: 116\n",
      "num_episode: 129; terminal_step: 10\n",
      "num_episode: 130; terminal_step: 41\n",
      "num_episode: 131; terminal_step: 31\n",
      "num_episode: 132; terminal_step: 76\n",
      "num_episode: 133; terminal_step: 32\n",
      "num_episode: 134; terminal_step: 100\n",
      "num_episode: 135; terminal_step: 122\n",
      "num_episode: 136; terminal_step: 18\n",
      "num_episode: 137; terminal_step: 63\n",
      "num_episode: 138; terminal_step: 87\n",
      "num_episode: 139; terminal_step: 20\n",
      "num_episode: 140; terminal_step: 46\n",
      "num_episode: 141; terminal_step: 107\n",
      "num_episode: 142; terminal_step: 39\n",
      "num_episode: 143; terminal_step: 109\n",
      "num_episode: 144; terminal_step: 86\n",
      "num_episode: 145; terminal_step: 26\n",
      "num_episode: 146; terminal_step: 13\n",
      "num_episode: 147; terminal_step: 11\n",
      "num_episode: 148; terminal_step: 95\n",
      "num_episode: 149; terminal_step: 120\n",
      "num_episode: 150; terminal_step: 25\n",
      "num_episode: 151; terminal_step: 36\n",
      "num_episode: 152; terminal_step: 203\n",
      "num_episode: 153; terminal_step: 196\n",
      "num_episode: 154; terminal_step: 174\n",
      "num_episode: 155; terminal_step: 134\n",
      "num_episode: 156; terminal_step: 262\n",
      "num_episode: 157; terminal_step: 142\n",
      "num_episode: 158; terminal_step: 221\n",
      "num_episode: 159; terminal_step: 182\n",
      "num_episode: 160; terminal_step: 155\n",
      "num_episode: 161; terminal_step: 154\n",
      "num_episode: 162; terminal_step: 500\n",
      "num_episode: 163; terminal_step: 81\n",
      "num_episode: 164; terminal_step: 122\n",
      "num_episode: 165; terminal_step: 20\n",
      "num_episode: 166; terminal_step: 113\n",
      "num_episode: 167; terminal_step: 190\n",
      "num_episode: 168; terminal_step: 375\n",
      "num_episode: 169; terminal_step: 119\n",
      "num_episode: 170; terminal_step: 136\n",
      "num_episode: 171; terminal_step: 109\n",
      "num_episode: 172; terminal_step: 89\n",
      "num_episode: 173; terminal_step: 118\n",
      "num_episode: 174; terminal_step: 120\n",
      "num_episode: 175; terminal_step: 127\n",
      "num_episode: 176; terminal_step: 242\n",
      "num_episode: 177; terminal_step: 73\n",
      "num_episode: 178; terminal_step: 112\n",
      "num_episode: 179; terminal_step: 116\n",
      "num_episode: 180; terminal_step: 119\n",
      "num_episode: 181; terminal_step: 182\n",
      "num_episode: 182; terminal_step: 500\n",
      "num_episode: 183; terminal_step: 145\n",
      "num_episode: 184; terminal_step: 102\n",
      "num_episode: 185; terminal_step: 136\n",
      "num_episode: 186; terminal_step: 385\n",
      "num_episode: 187; terminal_step: 385\n",
      "num_episode: 188; terminal_step: 187\n",
      "num_episode: 189; terminal_step: 207\n",
      "num_episode: 190; terminal_step: 359\n",
      "num_episode: 191; terminal_step: 114\n",
      "num_episode: 192; terminal_step: 440\n",
      "num_episode: 193; terminal_step: 195\n",
      "num_episode: 194; terminal_step: 135\n",
      "num_episode: 195; terminal_step: 148\n",
      "num_episode: 196; terminal_step: 140\n",
      "num_episode: 197; terminal_step: 159\n",
      "num_episode: 198; terminal_step: 299\n",
      "num_episode: 199; terminal_step: 262\n",
      "num_episode: 200; terminal_step: 272\n",
      "num_episode: 201; terminal_step: 214\n",
      "num_episode: 202; terminal_step: 164\n",
      "num_episode: 203; terminal_step: 109\n",
      "num_episode: 204; terminal_step: 105\n",
      "num_episode: 205; terminal_step: 123\n",
      "num_episode: 206; terminal_step: 13\n",
      "num_episode: 207; terminal_step: 10\n",
      "num_episode: 208; terminal_step: 43\n",
      "num_episode: 209; terminal_step: 8\n",
      "num_episode: 210; terminal_step: 47\n",
      "num_episode: 211; terminal_step: 62\n",
      "num_episode: 212; terminal_step: 110\n",
      "num_episode: 213; terminal_step: 8\n",
      "num_episode: 214; terminal_step: 500\n",
      "num_episode: 215; terminal_step: 9\n",
      "num_episode: 216; terminal_step: 11\n",
      "num_episode: 217; terminal_step: 12\n",
      "num_episode: 218; terminal_step: 15\n",
      "num_episode: 219; terminal_step: 14\n",
      "num_episode: 220; terminal_step: 16\n",
      "num_episode: 221; terminal_step: 81\n",
      "num_episode: 222; terminal_step: 65\n",
      "num_episode: 223; terminal_step: 13\n",
      "num_episode: 224; terminal_step: 15\n",
      "num_episode: 225; terminal_step: 18\n",
      "num_episode: 226; terminal_step: 9\n",
      "num_episode: 227; terminal_step: 10\n",
      "num_episode: 228; terminal_step: 142\n",
      "num_episode: 229; terminal_step: 148\n",
      "num_episode: 230; terminal_step: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episode: 231; terminal_step: 12\n",
      "num_episode: 232; terminal_step: 138\n",
      "num_episode: 233; terminal_step: 140\n",
      "num_episode: 234; terminal_step: 133\n",
      "num_episode: 235; terminal_step: 167\n",
      "num_episode: 236; terminal_step: 177\n",
      "num_episode: 237; terminal_step: 133\n",
      "num_episode: 238; terminal_step: 144\n",
      "num_episode: 239; terminal_step: 131\n",
      "num_episode: 240; terminal_step: 92\n",
      "num_episode: 241; terminal_step: 372\n",
      "num_episode: 242; terminal_step: 159\n",
      "num_episode: 243; terminal_step: 171\n",
      "num_episode: 244; terminal_step: 494\n",
      "num_episode: 245; terminal_step: 175\n",
      "num_episode: 246; terminal_step: 253\n",
      "num_episode: 247; terminal_step: 183\n",
      "num_episode: 248; terminal_step: 202\n",
      "num_episode: 249; terminal_step: 161\n",
      "num_episode: 250; terminal_step: 185\n",
      "CPU times: user 1min 9s, sys: 11.6 s, total: 1min 20s\n",
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_episodes = 250\n",
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('CartPole-v1')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_Default(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "#     clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "#         clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "    clf.experience_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55,\n",
       " 10,\n",
       " 10,\n",
       " 14,\n",
       " 13,\n",
       " 10,\n",
       " 25,\n",
       " 16,\n",
       " 27,\n",
       " 24,\n",
       " 35,\n",
       " 66,\n",
       " 12,\n",
       " 17,\n",
       " 23,\n",
       " 18,\n",
       " 10,\n",
       " 40,\n",
       " 32,\n",
       " 54,\n",
       " 91,\n",
       " 50,\n",
       " 25,\n",
       " 24,\n",
       " 47,\n",
       " 15,\n",
       " 12,\n",
       " 16,\n",
       " 54,\n",
       " 13,\n",
       " 23,\n",
       " 73,\n",
       " 17,\n",
       " 20,\n",
       " 9,\n",
       " 105,\n",
       " 106,\n",
       " 97,\n",
       " 63,\n",
       " 67,\n",
       " 111,\n",
       " 106,\n",
       " 15,\n",
       " 10,\n",
       " 49,\n",
       " 49,\n",
       " 103,\n",
       " 49,\n",
       " 43,\n",
       " 19,\n",
       " 51,\n",
       " 93,\n",
       " 47,\n",
       " 64,\n",
       " 25,\n",
       " 143,\n",
       " 145,\n",
       " 198,\n",
       " 112,\n",
       " 165,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 12,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 28,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 18,\n",
       " 35,\n",
       " 39,\n",
       " 20,\n",
       " 74,\n",
       " 15,\n",
       " 68,\n",
       " 10,\n",
       " 10,\n",
       " 18,\n",
       " 17,\n",
       " 30,\n",
       " 33,\n",
       " 13,\n",
       " 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.01 0\n",
      "num_episode: 1; terminal_step: 200\n",
      "num_episode: 2; terminal_step: 200\n",
      "num_episode: 3; terminal_step: 200\n",
      "num_episode: 4; terminal_step: 200\n",
      "num_episode: 5; terminal_step: 200\n",
      "num_episode: 6; terminal_step: 200\n",
      "num_episode: 7; terminal_step: 200\n",
      "num_episode: 8; terminal_step: 200\n",
      "num_episode: 9; terminal_step: 200\n",
      "num_episode: 10; terminal_step: 200\n",
      "num_episode: 11; terminal_step: 200\n",
      "num_episode: 12; terminal_step: 200\n",
      "num_episode: 13; terminal_step: 200\n",
      "num_episode: 14; terminal_step: 200\n",
      "num_episode: 15; terminal_step: 200\n",
      "num_episode: 16; terminal_step: 200\n",
      "num_episode: 17; terminal_step: 200\n",
      "num_episode: 18; terminal_step: 200\n",
      "num_episode: 19; terminal_step: 200\n",
      "num_episode: 20; terminal_step: 200\n",
      "num_episode: 21; terminal_step: 200\n",
      "num_episode: 22; terminal_step: 200\n",
      "num_episode: 23; terminal_step: 200\n",
      "num_episode: 24; terminal_step: 200\n",
      "num_episode: 25; terminal_step: 200\n",
      "num_episode: 26; terminal_step: 200\n",
      "num_episode: 27; terminal_step: 200\n",
      "num_episode: 28; terminal_step: 200\n",
      "num_episode: 29; terminal_step: 200\n",
      "num_episode: 30; terminal_step: 200\n",
      "num_episode: 31; terminal_step: 200\n",
      "num_episode: 32; terminal_step: 200\n",
      "num_episode: 33; terminal_step: 200\n",
      "num_episode: 34; terminal_step: 200\n",
      "num_episode: 35; terminal_step: 200\n",
      "num_episode: 36; terminal_step: 200\n",
      "num_episode: 37; terminal_step: 200\n",
      "num_episode: 38; terminal_step: 200\n",
      "num_episode: 39; terminal_step: 200\n",
      "num_episode: 40; terminal_step: 200\n",
      "num_episode: 41; terminal_step: 200\n",
      "num_episode: 42; terminal_step: 200\n",
      "num_episode: 43; terminal_step: 200\n",
      "num_episode: 44; terminal_step: 200\n",
      "num_episode: 45; terminal_step: 200\n",
      "num_episode: 46; terminal_step: 200\n",
      "num_episode: 47; terminal_step: 200\n",
      "num_episode: 48; terminal_step: 200\n",
      "num_episode: 49; terminal_step: 200\n",
      "num_episode: 50; terminal_step: 200\n",
      "num_episode: 51; terminal_step: 200\n",
      "num_episode: 52; terminal_step: 200\n",
      "num_episode: 53; terminal_step: 200\n",
      "num_episode: 54; terminal_step: 200\n",
      "num_episode: 55; terminal_step: 200\n",
      "num_episode: 56; terminal_step: 200\n",
      "num_episode: 57; terminal_step: 200\n",
      "num_episode: 58; terminal_step: 200\n",
      "num_episode: 59; terminal_step: 200\n",
      "num_episode: 60; terminal_step: 200\n",
      "num_episode: 61; terminal_step: 200\n",
      "num_episode: 62; terminal_step: 200\n",
      "num_episode: 63; terminal_step: 200\n",
      "num_episode: 64; terminal_step: 200\n",
      "num_episode: 65; terminal_step: 200\n",
      "num_episode: 66; terminal_step: 200\n",
      "num_episode: 67; terminal_step: 200\n",
      "num_episode: 68; terminal_step: 200\n",
      "num_episode: 69; terminal_step: 200\n",
      "num_episode: 70; terminal_step: 200\n",
      "num_episode: 71; terminal_step: 200\n",
      "num_episode: 72; terminal_step: 200\n",
      "num_episode: 73; terminal_step: 200\n",
      "num_episode: 74; terminal_step: 200\n",
      "num_episode: 75; terminal_step: 200\n",
      "num_episode: 76; terminal_step: 200\n",
      "num_episode: 77; terminal_step: 200\n",
      "num_episode: 78; terminal_step: 200\n",
      "num_episode: 79; terminal_step: 200\n",
      "num_episode: 80; terminal_step: 200\n",
      "num_episode: 81; terminal_step: 200\n",
      "num_episode: 82; terminal_step: 200\n",
      "num_episode: 83; terminal_step: 200\n",
      "num_episode: 84; terminal_step: 200\n",
      "num_episode: 85; terminal_step: 200\n",
      "num_episode: 86; terminal_step: 200\n",
      "num_episode: 87; terminal_step: 200\n",
      "num_episode: 88; terminal_step: 200\n",
      "num_episode: 89; terminal_step: 200\n",
      "num_episode: 90; terminal_step: 200\n",
      "num_episode: 91; terminal_step: 200\n",
      "num_episode: 92; terminal_step: 200\n",
      "num_episode: 93; terminal_step: 200\n",
      "num_episode: 94; terminal_step: 200\n",
      "num_episode: 95; terminal_step: 200\n",
      "num_episode: 96; terminal_step: 200\n",
      "num_episode: 97; terminal_step: 200\n",
      "num_episode: 98; terminal_step: 200\n",
      "num_episode: 99; terminal_step: 200\n",
      "num_episode: 100; terminal_step: 200\n"
     ]
    }
   ],
   "source": [
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('MountainCar-v0')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_HER(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "    clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "        clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "        clf.experience_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.01 0\n",
      "num_episode: 1; terminal_step: 200\n",
      "num_episode: 2; terminal_step: 200\n",
      "num_episode: 3; terminal_step: 200\n",
      "num_episode: 4; terminal_step: 200\n",
      "num_episode: 5; terminal_step: 200\n",
      "num_episode: 6; terminal_step: 200\n",
      "num_episode: 7; terminal_step: 200\n",
      "num_episode: 8; terminal_step: 200\n",
      "num_episode: 9; terminal_step: 200\n",
      "num_episode: 10; terminal_step: 200\n",
      "num_episode: 11; terminal_step: 200\n",
      "num_episode: 12; terminal_step: 200\n",
      "num_episode: 13; terminal_step: 200\n",
      "num_episode: 14; terminal_step: 200\n",
      "num_episode: 15; terminal_step: 200\n",
      "num_episode: 16; terminal_step: 200\n",
      "num_episode: 17; terminal_step: 200\n",
      "num_episode: 18; terminal_step: 200\n",
      "num_episode: 19; terminal_step: 200\n",
      "num_episode: 20; terminal_step: 200\n",
      "num_episode: 21; terminal_step: 200\n",
      "num_episode: 22; terminal_step: 200\n",
      "num_episode: 23; terminal_step: 200\n",
      "num_episode: 24; terminal_step: 200\n",
      "num_episode: 25; terminal_step: 200\n",
      "num_episode: 26; terminal_step: 200\n",
      "num_episode: 27; terminal_step: 200\n",
      "num_episode: 28; terminal_step: 200\n",
      "num_episode: 29; terminal_step: 200\n",
      "num_episode: 30; terminal_step: 200\n",
      "num_episode: 31; terminal_step: 200\n",
      "num_episode: 32; terminal_step: 200\n",
      "num_episode: 33; terminal_step: 200\n",
      "num_episode: 34; terminal_step: 200\n",
      "num_episode: 35; terminal_step: 200\n",
      "num_episode: 36; terminal_step: 200\n",
      "num_episode: 37; terminal_step: 200\n",
      "num_episode: 38; terminal_step: 200\n",
      "num_episode: 39; terminal_step: 200\n",
      "num_episode: 40; terminal_step: 200\n",
      "num_episode: 41; terminal_step: 200\n",
      "num_episode: 42; terminal_step: 200\n",
      "num_episode: 43; terminal_step: 200\n",
      "num_episode: 44; terminal_step: 200\n",
      "num_episode: 45; terminal_step: 200\n",
      "num_episode: 46; terminal_step: 200\n",
      "num_episode: 47; terminal_step: 200\n",
      "num_episode: 48; terminal_step: 200\n",
      "num_episode: 49; terminal_step: 200\n",
      "num_episode: 50; terminal_step: 200\n",
      "num_episode: 51; terminal_step: 200\n",
      "num_episode: 52; terminal_step: 200\n",
      "num_episode: 53; terminal_step: 200\n",
      "num_episode: 54; terminal_step: 200\n",
      "num_episode: 55; terminal_step: 200\n",
      "num_episode: 56; terminal_step: 200\n",
      "num_episode: 57; terminal_step: 200\n",
      "num_episode: 58; terminal_step: 200\n",
      "num_episode: 59; terminal_step: 200\n",
      "num_episode: 60; terminal_step: 200\n",
      "num_episode: 61; terminal_step: 200\n",
      "num_episode: 62; terminal_step: 200\n",
      "num_episode: 63; terminal_step: 200\n",
      "num_episode: 64; terminal_step: 200\n",
      "num_episode: 65; terminal_step: 200\n",
      "num_episode: 66; terminal_step: 200\n",
      "num_episode: 67; terminal_step: 200\n",
      "num_episode: 68; terminal_step: 200\n",
      "num_episode: 69; terminal_step: 200\n",
      "num_episode: 70; terminal_step: 200\n",
      "num_episode: 71; terminal_step: 200\n",
      "num_episode: 72; terminal_step: 200\n",
      "num_episode: 73; terminal_step: 200\n",
      "num_episode: 74; terminal_step: 200\n",
      "num_episode: 75; terminal_step: 200\n",
      "num_episode: 76; terminal_step: 200\n",
      "num_episode: 77; terminal_step: 200\n",
      "num_episode: 78; terminal_step: 200\n",
      "num_episode: 79; terminal_step: 200\n",
      "num_episode: 80; terminal_step: 200\n",
      "num_episode: 81; terminal_step: 200\n",
      "num_episode: 82; terminal_step: 200\n",
      "num_episode: 83; terminal_step: 200\n",
      "num_episode: 84; terminal_step: 200\n",
      "num_episode: 85; terminal_step: 200\n",
      "num_episode: 86; terminal_step: 200\n",
      "num_episode: 87; terminal_step: 200\n",
      "num_episode: 88; terminal_step: 200\n",
      "num_episode: 89; terminal_step: 200\n",
      "num_episode: 90; terminal_step: 200\n",
      "num_episode: 91; terminal_step: 200\n",
      "num_episode: 92; terminal_step: 200\n",
      "num_episode: 93; terminal_step: 200\n",
      "num_episode: 94; terminal_step: 200\n",
      "num_episode: 95; terminal_step: 200\n",
      "num_episode: 96; terminal_step: 200\n",
      "num_episode: 97; terminal_step: 200\n",
      "num_episode: 98; terminal_step: 200\n",
      "num_episode: 99; terminal_step: 200\n",
      "num_episode: 100; terminal_step: 200\n"
     ]
    }
   ],
   "source": [
    "print(buffer, lr, seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "eps_steps = []\n",
    "env = gym.make('MountainCar-v0')\n",
    "o_space = env.observation_space.shape[0]\n",
    "a_space = env.action_space.n\n",
    "\n",
    "clf = Q_Learning_Default(o_space, a_space, buffer, lr, n_step)\n",
    "\n",
    "num_episode = 0\n",
    "\n",
    "for num_episode in range(1, max_episodes+1):# while True:\n",
    "    s = env.reset()\n",
    "    s = np.reshape(s, [1, o_space])\n",
    "#     clf.reset_her()\n",
    "\n",
    "    num_step = 0\n",
    "    while True:\n",
    "        num_step += 1\n",
    "\n",
    "        a = clf.get_action(s)\n",
    "\n",
    "        s_next, r, terminal, _ = env.step(a)\n",
    "        s_next = np.reshape(s_next, [1, o_space])\n",
    "\n",
    "        if terminal:\n",
    "            r = -r\n",
    "        else:\n",
    "            r = r\n",
    "        \n",
    "        clf.add_experience(s, a, r, s_next, terminal)\n",
    "#         clf.add_her_experience(s, a, r, s_next, terminal)\n",
    "\n",
    "        s = s_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"num_episode: {num_episode}; terminal_step: {num_step}\".format(num_episode=num_episode, num_step=num_step))\n",
    "            eps_steps.append(num_step)\n",
    "            break\n",
    "\n",
    "        clf.experience_replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp3",
   "language": "python",
   "name": "mlp3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
